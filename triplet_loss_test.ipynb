{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 导入packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.backends:backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os, sys, random\n",
    "import matplotlib as mpl\n",
    "import tarfile\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet.gluon import nn, utils\n",
    "from mxnet.gluon.nn import Dense, Activation, Conv2D, Conv2DTranspose, \\\n",
    "    BatchNorm, LeakyReLU, Flatten, HybridSequential, HybridBlock, Dropout\n",
    "from mxnet import autograd\n",
    "import numpy as np\n",
    "\n",
    "from mxboard import SummaryWriter\n",
    "\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 定义数据集类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(gluon.data.dataset.Dataset):\n",
    "    def __init__(self, rd, rl, transform=None):\n",
    "        self.__rd = rd  # 原始数据\n",
    "        self.__rl = rl  # 原始标签\n",
    "        self._data = None\n",
    "        self._label = None\n",
    "        self._transform = transform\n",
    "        self._get_data()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self._transform is not None:\n",
    "            return self._transform(self._data[idx], self._label[idx])\n",
    "        return self._data[idx], self._label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._label)\n",
    "\n",
    "    def _get_data(self):\n",
    "        label_list = np.unique(self.__rl)\n",
    "        digit_indices = [np.where(self.__rl == i)[0] for i in label_list]\n",
    "        tl_pairs = self.create_pairs(self.__rd, digit_indices, len(label_list))\n",
    "        self._data = tl_pairs\n",
    "        self._label = np.ones(tl_pairs.shape[0])\n",
    "\n",
    "    @staticmethod\n",
    "    def create_pairs(x, digit_indices, num_classes):\n",
    "        x = x.asnumpy()  # 转换数据格式\n",
    "        pairs = []\n",
    "        n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1  # 最小类别数\n",
    "        for d in range(num_classes):\n",
    "            for i in range(n):\n",
    "                np.random.shuffle(digit_indices[d])\n",
    "                z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "                inc = random.randrange(1, num_classes)\n",
    "                dn = (d + inc) % num_classes\n",
    "                z3 = digit_indices[dn][i]\n",
    "                pairs += [[x[z1], x[z2], x[z3]]]\n",
    "        return np.asarray(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_net(model, test_data, ctx=mx.cpu() ):\n",
    "    triplet_loss = gluon.loss.TripletLoss(margin=0)\n",
    "    sum_correct = 0.0\n",
    "    sum_all = 0\n",
    "    rate = 0.0\n",
    "    for i, (data, _) in enumerate(test_data):\n",
    "        data = data.as_in_context(ctx)\n",
    "\n",
    "        anc_ins, pos_ins, neg_ins = data[:, 0], data[:, 1], data[:, 2]\n",
    "        \n",
    "        inter1 = model(anc_ins)  # 训练的时候组合\n",
    "        inter2 = model(pos_ins)\n",
    "        inter3 = model(neg_ins)\n",
    "#         print( inter1.shape )\n",
    "        loss = triplet_loss(inter1, inter2, inter3)\n",
    "\n",
    "        loss = loss.asnumpy()\n",
    "        n_all = loss.shape[0]\n",
    "        n_correct = np.sum(np.where(loss == 0, 1, 0))\n",
    "\n",
    "        sum_correct += n_correct\n",
    "        sum_all += n_all\n",
    "    rate = sum_correct / sum_all\n",
    "\n",
    "#     print('accuracy : %.4f (%s / %s)' % (rate, sum_correct, sum_all))\n",
    "    return rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* np.where是找到满足条件的下标，可以加上x和y两个参数，会返回一个矩阵，满足条件的值得位置赋值为x，不满足的为y。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2 -1 -2]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([2,1,3])\n",
    "b = np.where( a == 1, -1, -2 )\n",
    "print( b )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 导入数据，设置训练的一些参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu()\n",
    "batch_size = 1024\n",
    "random.seed(47)\n",
    "mnist_data_dir = '../dataset/mnist'\n",
    "\n",
    "mnist_train = gluon.data.vision.MNIST(train=True, root=mnist_data_dir)  # load train data\n",
    "tr_data = mnist_train._data.reshape((-1, 28 * 28)) \n",
    "tr_label = mnist_train._label  # 标签\n",
    "\n",
    "mnist_test = gluon.data.vision.MNIST(train=False, root=mnist_data_dir)  # load test data\n",
    "te_data = mnist_test._data.reshape((-1, 28 * 28))\n",
    "te_label = mnist_test._label\n",
    "\n",
    "def transform(data_, label_):\n",
    "    return data_.astype(np.float32) / 255., label_.astype(np.float32)\n",
    "\n",
    "train_data = gluon.data.DataLoader(\n",
    "    TripletDataset(rd=tr_data, rl=tr_label, transform=transform),\n",
    "    batch_size, shuffle=True)\n",
    "\n",
    "test_data = gluon.data.DataLoader(\n",
    "    TripletDataset(rd=te_data, rl=te_label, transform=transform),\n",
    "    batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "base_net = gluon.nn.Sequential()\n",
    "with base_net.name_scope():\n",
    "    base_net.add(gluon.nn.Dense(256, activation='relu'))\n",
    "    base_net.add(gluon.nn.Dense(128, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 定义triplet loss，开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Triplet Loss: 0.28602317, validation accuracy : 0.877329\n",
      "Epoch: 10, Triplet Loss: 0.0814259, validation accuracy : 0.954658\n",
      "Epoch: 20, Triplet Loss: 0.0684311, validation accuracy : 0.963524\n",
      "Epoch: 30, Triplet Loss: 0.0485348, validation accuracy : 0.968126\n",
      "Epoch: 40, Triplet Loss: 0.03245996, validation accuracy : 0.970034\n",
      "Epoch: 50, Triplet Loss: 0.030095275, validation accuracy : 0.971829\n",
      "Epoch: 60, Triplet Loss: 0.024903722, validation accuracy : 0.973625\n",
      "Epoch: 70, Triplet Loss: 0.010364741, validation accuracy : 0.973513\n",
      "Epoch: 80, Triplet Loss: 0.015544275, validation accuracy : 0.973962\n",
      "Epoch: 90, Triplet Loss: 0.007999075, validation accuracy : 0.974411\n"
     ]
    }
   ],
   "source": [
    "base_net.collect_params().initialize(mx.init.Uniform(scale=0.1), ctx=ctx, force_reinit=True)\n",
    "\n",
    "triplet_loss = gluon.loss.TripletLoss()  # TripletLoss损失函数\n",
    "trainer_triplet = gluon.Trainer(base_net.collect_params(), 'sgd', {'learning_rate': 0.03})\n",
    "\n",
    "for epoch in range(100):\n",
    "    curr_loss = 0.0\n",
    "    for i, (data, _) in enumerate(train_data):\n",
    "        data = data.as_in_context(ctx)\n",
    "        anc_ins, pos_ins, neg_ins = data[:, 0], data[:, 1], data[:, 2]\n",
    "        with autograd.record():\n",
    "            inter1 = base_net(anc_ins)\n",
    "            inter2 = base_net(pos_ins)\n",
    "            inter3 = base_net(neg_ins)\n",
    "            loss = triplet_loss(inter1, inter2, inter3)  # Triplet Loss\n",
    "        loss.backward()\n",
    "        trainer_triplet.step(batch_size)\n",
    "        curr_loss = mx.nd.mean(loss).asscalar()\n",
    "        # print('Epoch: %s, Batch: %s, Triplet Loss: %s' % (epoch, i, curr_loss))\n",
    "    if epoch % 10 == 0:\n",
    "        val_acc = evaluate_net(base_net, test_data, ctx=ctx)\n",
    "        print('Epoch: %s, Triplet Loss: %s, validation accuracy : %f' % (epoch, curr_loss, val_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 使用tensorboard进行emebedding的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mxboard.event_file_writer:successfully opened events file: ./logs/events.out.tfevents.1544098248.ININ-Z640\n",
      "INFO:mxboard.writer:saved embedding labels to ./logs/mnist_codes\n",
      "INFO:mxboard.event_file_writer:wrote 1 event to disk\n",
      "INFO:mxboard.writer:saved embedding images to ./logs/mnist_codes\n",
      "INFO:mxboard.event_file_writer:wrote 1 event to disk\n",
      "INFO:mxboard.writer:saved embedding data to ./logs/mnist_codes\n"
     ]
    }
   ],
   "source": [
    "trans_te_data, trans_te_label = transform(te_data, te_label)\n",
    "trans_te_data = trans_te_data[0:1000]\n",
    "trans_te_label = trans_te_label[0:1000]\n",
    "trans_te_label = mx.nd.array( trans_te_label )\n",
    "# tb_projector(trans_te_data.asnumpy(), trans_te_label, os.path.join(ROOT_DIR, 'logs', 'origin'))\n",
    "# 如果需要看初始时刻的embedding情况，可以强制初始化\n",
    "# base_net.collect_params().initialize(mx.init.Uniform(scale=0.1), ctx=ctx, force_reinit=True)\n",
    "trans_te_res = base_net(trans_te_data.as_in_context( context=ctx ))\n",
    "\n",
    "# 转换成4D数据 NCHW\n",
    "trans_te_data = trans_te_data.reshape( (-1,28,28))\n",
    "trans_te_data = mx.nd.expand_dims( trans_te_data, axis=(1) )\n",
    "\n",
    "label_str = [str(int(idx)) for idx in trans_te_label.asnumpy()]\n",
    "\n",
    "with SummaryWriter(logdir='./logs') as sw:\n",
    "    sw.add_image(tag='mnists', image=trans_te_data)\n",
    "    sw.add_embedding(tag='mnist_codes', embedding=trans_te_res, images=trans_te_data, labels=label_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9750841750841751\n"
     ]
    }
   ],
   "source": [
    "print( evaluate_net(base_net, test_data, ctx=ctx) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
